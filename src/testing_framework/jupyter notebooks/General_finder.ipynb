{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General finder\n",
    "\n",
    "* The purpose of this notebook is to try to turn the hybrid merger into a general merge algorithm\n",
    "* We will also add a non-hybrid and hybrid labelling after alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1963fedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from testing_framework import testing_utils\n",
    "import database\n",
    "from preprocessing import preprocessing_utils, merge_search, clustering\n",
    "from identification import create_hits\n",
    "from gen_spectra import get_precursor, gen_spectrum\n",
    "import utils\n",
    "\n",
    "import operator\n",
    "\n",
    "max_peptide_length = 23\n",
    "ppm_tolerance = 20\n",
    "precursor_tolerance = 10\n",
    "peak_filter = 25\n",
    "relative_abundance_filter = 0.1\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1adbddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = testing_utils.define_data()\n",
    "\n",
    "dataset = datasets[0]\n",
    "\n",
    "input_spectra_path = [os.path.join(dataset[0], 'NOD2_E3.mzML')]\n",
    "input_spectra, boundaries = preprocessing_utils.load_spectra(input_spectra_path, ppm_tolerance, peak_filter=peak_filter, relative_abundance_filter=relative_abundance_filter)\n",
    "\n",
    "correct_sequences = testing_utils.generate_truth_set(datasets[0])\n",
    "\n",
    "path = dataset[2]\n",
    "db = database.build(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a61567a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On protein 279/279 [100%]\n",
      "Sorting the set of protein masses...\n",
      "Sorting the set of protein masses done\n",
      "Performing Merge\n",
      "Done\n",
      "Finished matching masses\n"
     ]
    }
   ],
   "source": [
    "write_path = os.path.abspath(os.path.join(module_path, 'intermediate_files'))\n",
    "matched_masses_b, matched_masses_y, kmer_set = merge_search.modified_match_masses(boundaries, db, max_peptide_length, True, write_path)\n",
    "print('Finished matching masses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DPQVEQLEL\n",
      "21653 22360 26331 1086\n",
      "20187 19757 20187\n"
     ]
    }
   ],
   "source": [
    "spectrum_num = 0\n",
    "\n",
    "correct_sequence = correct_sequences[spectrum_num]\n",
    "print(correct_sequence)\n",
    "\n",
    "input_spectrum = input_spectra[spectrum_num]\n",
    "location = os.path.join(os.path.abspath(os.path.join('../..')), 'intermediate_files/')\n",
    "b_hits, y_hits = create_hits(spectrum_num, input_spectrum, matched_masses_b, matched_masses_y, False, location)\n",
    "correct_hits = testing_utils.append_correct_hits(correct_sequence, input_spectrum, ppm_tolerance)\n",
    "ion = 'b'\n",
    "clusters = testing_utils.create_clusters(ion, b_hits, y_hits)\n",
    "b_sorted_clusters = clustering.Score_clusters(ion, clusters)\n",
    "ion = 'y'\n",
    "clusters = testing_utils.create_clusters(ion, b_hits, y_hits)\n",
    "y_sorted_clusters = clustering.Score_clusters(ion, clusters)\n",
    "with open(os.path.join(location, 'b_sorted_clusters.txt'), 'w') as b:\n",
    "    [b.write(str(x) + '\\n') for x in b_sorted_clusters]\n",
    "with open(os.path.join(location, 'y_sorted_clusters.txt'), 'w') as y:\n",
    "    [y.write(str(x) + '\\n') for x in y_sorted_clusters]\n",
    "print(len(b_hits), len(y_hits), len(boundaries), len(input_spectra))\n",
    "print(len(clusters), len(b_sorted_clusters), len(y_sorted_clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160994\n",
      "(7, 2431, -2424, (278, 148, 149, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2378, -2371, (278, 201, 202, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2377, -2370, (278, 202, 203, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2302, -2295, (278, 277, 278, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2448, -2441, (275, 131, 132, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2430, -2423, (273, 149, 150, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2376, -2369, (273, 203, 204, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2275, -2268, (273, 304, 305, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2293, -2286, (269, 286, 287, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2042, -2035, (269, 537, 538, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2472, -2465, (266, 107, 108, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2395, -2388, (264, 184, 185, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2331, -2324, (264, 248, 249, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2570, -2563, (261, 9, 10, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2452, -2445, (261, 127, 128, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2493, -2486, (259, 86, 87, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2429, -2422, (259, 150, 151, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2544, -2537, (257, 35, 36, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2543, -2536, (256, 36, 37, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2466, -2459, (254, 113, 114, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2459, -2452, (254, 120, 121, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2308, -2301, (253, 271, 272, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2052, -2045, (253, 527, 528, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2574, -2567, (251, 5, 6, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2254, -2247, (249, 325, 326, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2187, -2180, (249, 392, 393, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2161, -2154, (249, 418, 419, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2160, -2153, (249, 419, 420, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2159, -2152, (249, 420, 421, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2139, -2132, (249, 440, 441, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2138, -2131, (249, 441, 442, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2137, -2130, (249, 442, 443, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2119, -2112, (249, 460, 461, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2100, -2093, (249, 479, 480, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2099, -2092, (249, 480, 481, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2053, -2046, (249, 526, 527, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2052, -2045, (249, 527, 528, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 1743, -1736, (249, 836, 837, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2477, -2470, (245, 102, 103, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2453, -2446, (245, 126, 127, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2501, -2494, (244, 78, 79, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2442, -2435, (244, 137, 138, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2121, -2114, (243, 458, 459, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2442, -2435, (240, 137, 138, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2285, -2278, (238, 294, 295, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2239, -2232, (238, 340, 341, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2413, -2406, (235, 166, 167, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2261, -2254, (233, 318, 319, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2427, -2420, (232, 152, 153, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n",
      "(7, 2349, -2342, (229, 230, 231, 2, 'TT'), (158, 2573, 2579, 5, 'LDSFSEI'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from constants import WATER_MASS, PROTON_MASS\n",
    "import collections\n",
    "\n",
    "def min_info(cluster):\n",
    "    return (cluster.pid, cluster.start, cluster.end, cluster.score, cluster.seq)\n",
    "\n",
    "def check_for_hybrid_overlap(b_seq, y_seq, ion):\n",
    "    match = True\n",
    "    if ion == 'b':\n",
    "        for i, char in enumerate(b_seq):\n",
    "            if char == y_seq[0]:\n",
    "                k = 0\n",
    "                for j in range(i, len(b_seq) + 1):\n",
    "                    if b_seq[j] != y_seq[k]:\n",
    "                        match = False\n",
    "                        break\n",
    "        if match == True:\n",
    "            print('Match was true for', b_seq)\n",
    "            modified_seq = b_seq[:i]\n",
    "    else:\n",
    "        for i, char in enumerate(y_seq):\n",
    "            if char == y_seq[0]:\n",
    "                k = 0\n",
    "                for j in range(i, len(b_seq) + 1):\n",
    "                    if b_seq[j] != y_seq[k]:\n",
    "                        match = False\n",
    "                        break\n",
    "        if match == True:\n",
    "            print('Match was true for', b_seq)\n",
    "            modified_seq = b_seq[:i]\n",
    "    return match, modified_seq\n",
    "\n",
    "def grab_matches(b,indexed_clusters, target_val, ion):\n",
    "    #Given a cluster we want to find everything that it can pair with\n",
    "    # It can pair with anything up to a certain mass \n",
    "    current_index = 0\n",
    "    matches = []\n",
    "    for key in indexed_clusters.keys():\n",
    "        if key<=target_val: #if key is a valid key\n",
    "            for y in indexed_clusters[key]:\n",
    "                if ion == 'b':\n",
    "                    matches.append((b.score + y.score, b.end - y.start, y.end-b.start,min_info(b), min_info(y)))\n",
    "                else:\n",
    "                    matches.append((b.score + y.score, b.end - y.start, y.end-b.start,min_info(y), min_info(b)))\n",
    "        else:\n",
    "#             match, modified_seq = check_for_hybrid_overlap()\n",
    "            break            \n",
    "    return matches\n",
    "    \n",
    "def index_by_precursor_mass(sorted_clusters, pc):\n",
    "    indexed = dict()\n",
    "    for y in sorted_clusters:\n",
    "        if get_precursor(y.seq, pc) not in indexed.keys():\n",
    "            indexed[get_precursor(y.seq, pc)] = []\n",
    "        indexed[get_precursor(y.seq, pc)].append(y)\n",
    "    indexed = collections.OrderedDict(sorted(indexed.items(),key=lambda t: t[0]))\n",
    "    return indexed\n",
    "    \n",
    "def get_matches(b_sorted_clusters, y_sorted_clusters, obs_prec, precursor_tol, charge):\n",
    "    merged_seqs = []\n",
    "    ind_b, ind_y = index_by_precursor_mass(b_sorted_clusters, charge),index_by_precursor_mass(y_sorted_clusters, charge)\n",
    "    for i, cluster in enumerate(b_sorted_clusters[:10]):\n",
    "        cluster_seq = cluster.seq\n",
    "        cluster_mass = get_precursor(cluster_seq, charge)\n",
    "        tol = utils.ppm_to_da(obs_prec, precursor_tol)\n",
    "        if not (cluster_mass > obs_prec + tol):\n",
    "            diff = obs_prec + tol - cluster_mass + (charge * PROTON_MASS) + WATER_MASS\n",
    "            merges = grab_matches(cluster,ind_y, diff, 'b')\n",
    "            [merged_seqs.append(x) for x in merges]\n",
    "    for i, cluster in enumerate(y_sorted_clusters[:10]):\n",
    "        cluster_seq = cluster.seq\n",
    "        cluster_mass = get_precursor(cluster_seq, charge)\n",
    "        tol = utils.ppm_to_da(obs_prec, precursor_tol)\n",
    "        if not (cluster_mass > obs_prec + tol):\n",
    "            diff = obs_prec + tol - cluster_mass + (charge * PROTON_MASS) + WATER_MASS\n",
    "#             print(get_precursor(cluster_seq + 'DL', charge), obs_prec + tol)\n",
    "            merges = grab_matches(cluster,ind_b, diff, 'y')\n",
    "            [merged_seqs.append(x) for x in merges]\n",
    "\n",
    "    merged_seqs.sort(key=lambda a: a[0], reverse=True)\n",
    "    return merged_seqs\n",
    "\n",
    "#All inputs are the same\n",
    "merged_seqs = clustering.get_matches(b_sorted_clusters, y_sorted_clusters, input_spectrum.precursor_mass, precursor_tolerance, input_spectrum.precursor_charge)\n",
    "print(len(merged_seqs))\n",
    "[print(x) for x in merged_seqs[:50]]\n",
    "# with open(os.path.join(location, 'merged_seqs.txt'), 'w') as b:\n",
    "#     [b.write(str(x) + '\\n') for x in merged_seqs]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b6d3b7309614241360366c22e3841483b033a77cbf8e08d8178bcdf4d67dc4a0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
