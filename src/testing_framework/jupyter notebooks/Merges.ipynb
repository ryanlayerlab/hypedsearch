{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b350d988",
   "metadata": {},
   "source": [
    "# Extensions\n",
    "\n",
    "The purpose of this notebook is to test everything related to merging initial hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1963fedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from testing_framework import testing_utils\n",
    "import database\n",
    "from preprocessing import preprocessing_utils, merge_search, clustering\n",
    "from identification import create_hits\n",
    "from gen_spectra import get_precursor, gen_spectrum\n",
    "import utils\n",
    "\n",
    "import operator\n",
    "\n",
    "max_peptide_length = 23\n",
    "ppm_tolerance = 20\n",
    "precursor_tolerance = 10\n",
    "peak_filter = 25\n",
    "relative_abundance_filter = 0.1\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1adbddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = testing_utils.define_data()\n",
    "\n",
    "dataset = datasets[0]\n",
    "\n",
    "input_spectra_path = [os.path.join(dataset[0], 'NOD2_E3.mzML')]\n",
    "input_spectra, boundaries = preprocessing_utils.load_spectra(input_spectra_path, ppm_tolerance, peak_filter=peak_filter, relative_abundance_filter=relative_abundance_filter)\n",
    "\n",
    "correct_sequences = testing_utils.generate_truth_set(datasets[0])\n",
    "\n",
    "path = dataset[2]\n",
    "db = database.build(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a61567a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On protein 279/279 [100%]\n",
      "Sorting the set of protein masses...\n",
      "Sorting the set of protein masses done\n",
      "Performing Merge\n",
      "Done\n",
      "Finished matching masses\n"
     ]
    }
   ],
   "source": [
    "write_path = os.path.abspath(os.path.join(module_path, 'intermediate_files'))\n",
    "matched_masses_b, matched_masses_y, kmer_set = merge_search.modified_match_masses(boundaries, db, max_peptide_length, True, write_path)\n",
    "print('Finished matching masses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7eb077c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20410 20364\n"
     ]
    }
   ],
   "source": [
    "print(len(matched_masses_b), len(matched_masses_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cc516b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_b,unique_y = testing_utils.get_unique_matched_masses(boundaries, matched_masses_b, matched_masses_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339a6532",
   "metadata": {},
   "source": [
    "# Getting initial hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a63a71ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "148\n",
      "153\n",
      "154\n",
      "199\n",
      "202\n",
      "206\n",
      "248\n",
      "249\n",
      "251\n",
      "263\n",
      "266\n",
      "269\n",
      "277\n",
      "278\n",
      "309\n",
      "318\n",
      "323\n",
      "445\n",
      "449\n",
      "453\n",
      "458\n",
      "460\n",
      "483\n",
      "498\n",
      "518\n",
      "519\n",
      "528\n",
      "596\n",
      "597\n",
      "600\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "679\n",
      "689\n",
      "695\n",
      "699\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "745\n",
      "768\n",
      "784\n",
      "802\n",
      "854\n",
      "855\n",
      "898\n",
      "905\n",
      "906\n",
      "950\n",
      "953\n",
      "954\n",
      "1023\n",
      "1032\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1074\n",
      "1079\n"
     ]
    }
   ],
   "source": [
    "for i, seq in enumerate(correct_sequences):\n",
    "    if len(seq) > 30:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeeed96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLPVNSPMTKG\n"
     ]
    }
   ],
   "source": [
    "spectrum_num = 6\n",
    "\n",
    "correct_sequence = correct_sequences[spectrum_num]\n",
    "print(correct_sequence)\n",
    "\n",
    "input_spectrum = input_spectra[spectrum_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ded1f3c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5c76359bfda7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mb_sorted_clusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtesting_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBayes_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkmer_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mclusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtesting_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_hits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0my_sorted_clusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtesting_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBayes_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkmer_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b_sorted_clusters.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jaime_hypedsearch/hypedsearch/src/testing_framework/testing_utils.py\u001b[0m in \u001b[0;36mcreate_clusters\u001b[0;34m(ion, b_hits, y_hits)\u001b[0m\n\u001b[1;32m   1012\u001b[0m                 \u001b[0mlast_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         \u001b[0mhits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_hits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0msorted_hits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'start'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0mlast_pid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jaime_hypedsearch/hypedsearch/src/testing_framework/testing_utils.py\u001b[0m in \u001b[0;36mparse_hits\u001b[0;34m(Hit, all_hits)\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mA\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_hits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "location = os.path.join(os.path.abspath(os.path.join('../..')), 'intermediate_files/')\n",
    "b_hits, y_hits = create_hits(spectrum_num, input_spectrum, matched_masses_b, matched_masses_y, False, location)\n",
    "correct_hits = testing_utils.append_correct_hits(correct_sequence, input_spectrum, ppm_tolerance)\n",
    "ion = 'b'\n",
    "clusters = testing_utils.create_clusters(ion, b_hits, y_hits)\n",
    "b_sorted_clusters = testing_utils.Bayes_clusters(ion, clusters, location, kmer_set, unique_b)\n",
    "ion = 'y'\n",
    "clusters = testing_utils.create_clusters(ion, b_hits, y_hits)\n",
    "y_sorted_clusters = testing_utils.Bayes_clusters(ion, clusters, location, kmer_set, unique_y)\n",
    "with open(os.path.join(location, 'b_sorted_clusters.txt'), 'w') as b:\n",
    "    [b.write(str(x) + '\\n') for x in b_sorted_clusters]\n",
    "with open(os.path.join(location, 'y_sorted_clusters.txt'), 'w') as y:\n",
    "    [y.write(str(x) + '\\n') for x in y_sorted_clusters]\n",
    "print(len(b_hits), len(y_hits), len(boundaries), len(input_spectra))\n",
    "print(len(clusters), len(b_sorted_clusters), len(y_sorted_clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa96fc44",
   "metadata": {},
   "source": [
    "# Printing hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00538a18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b_sorted_clusters = sorted(b_sorted_clusters, key=operator.attrgetter('score', 'pid'), reverse = True)\n",
    "testing_utils.write_b_sorted_cluster(b_sorted_clusters)\n",
    "for i in range(0, 50):\n",
    "    x = b_sorted_clusters[i]\n",
    "    score = x.score\n",
    "    seq = x.seq\n",
    "    print(score, seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e39bb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_sorted_clusters = sorted(y_sorted_clusters, key=operator.attrgetter('prob', 'score', 'pid'))\n",
    "# y_sorted_clusters = sorted(y_sorted_clusters, key=operator.attrgetter('score', 'prob', 'pid'), reverse = True)\n",
    "testing_utils.write_y_sorted_cluster(y_sorted_clusters)\n",
    "for i in range(0, 50):\n",
    "    x = y_sorted_clusters[i]\n",
    "    score = x.score\n",
    "    seq = x.seq\n",
    "    print(score, seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce996c48",
   "metadata": {},
   "source": [
    "# Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b520e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = clustering.Ryan_merge(b_sorted_clusters, y_sorted_clusters)\n",
    "m.sort(key = lambda x: x[0], reverse = True)\n",
    "[print(m[x]) for x in range(0,10)]\n",
    "print(len(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c58c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_precursor(mseqs, obs_prec, precursor_tol, charge):\n",
    "    filtered_seqs = []\n",
    "    for comb_seq in mseqs:\n",
    "        b_seq = comb_seq[3][4]\n",
    "        y_seq = comb_seq[4][4]\n",
    "        if b_seq != y_seq:\n",
    "            new_seq = b_seq + y_seq\n",
    "        else:\n",
    "            new_seq = b_seq\n",
    "        tol = utils.ppm_to_da(obs_prec, precursor_tol)\n",
    "        if not (get_precursor(new_seq, charge) > obs_prec + tol):\n",
    "            filtered_seqs.append(comb_seq)\n",
    "    return filtered_seqs\n",
    "\n",
    "m = filter_by_precursor(m, input_spectrum.precursor_mass, precursor_tolerance, input_spectrum.precursor_charge)\n",
    "[print(m[x]) for x in range(0,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d39ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(m))\n",
    "print(m[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18d2b6c",
   "metadata": {},
   "source": [
    "# Hybrid Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505bbf74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from constants import WATER_MASS, PROTON_MASS\n",
    "import collections\n",
    "\n",
    "def min_info(cluster):\n",
    "    return (cluster.pid, cluster.start, cluster.end, cluster.score, cluster.seq)\n",
    "\n",
    "def check_for_hybrid_overlap(b_seq, y_seq, ion):\n",
    "    match = True\n",
    "    print('code got here')\n",
    "    if ion == 'b':\n",
    "        for i, char in enumerate(b_seq):\n",
    "            if char == y_seq[0]:\n",
    "                k = 0\n",
    "                for j in range(i, len(b_seq) + 1):\n",
    "                    if b_seq[j] != y_seq[k]:\n",
    "                        match = False\n",
    "                        break\n",
    "        if match == True:\n",
    "            print('Match was true for', b_seq)\n",
    "            modified_seq = b_seq[:i]\n",
    "    else:\n",
    "        for i, char in enumerate(y_seq):\n",
    "            if char == y_seq[0]:\n",
    "                k = 0\n",
    "                for j in range(i, len(b_seq) + 1):\n",
    "                    if b_seq[j] != y_seq[k]:\n",
    "                        match = False\n",
    "                        break\n",
    "        if match == True:\n",
    "            print('Match was true for', b_seq)\n",
    "            modified_seq = b_seq[:i]\n",
    "    return match, modified_seq\n",
    "\n",
    "def grab_matches(b,indexed_clusters, target_val, ion):\n",
    "    #Given a cluster we want to find everything that it can pair with\n",
    "    # It can pair with anything up to a certain mass \n",
    "    current_index = 0\n",
    "    matches = []\n",
    "    for key in indexed_clusters.keys():\n",
    "        if key<=target_val: #if key is a valid key\n",
    "            for y in indexed_clusters[key]:\n",
    "                if ion == 'b':\n",
    "                    matches.append((b.score + y.score, b.end - y.start, y.end-b.start,min_info(b), min_info(y)))\n",
    "                else:\n",
    "                    matches.append((b.score + y.score, b.end - y.start, y.end-b.start,min_info(y), min_info(b)))\n",
    "        else:\n",
    "#             match, modified_seq = check_for_hybrid_overlap()\n",
    "            break            \n",
    "    return matches\n",
    "    \n",
    "def index_by_precursor_mass(sorted_clusters, pc):\n",
    "    indexed = dict()\n",
    "    for y in sorted_clusters:\n",
    "        if get_precursor(y.seq, pc) not in indexed.keys():\n",
    "            indexed[get_precursor(y.seq, pc)] = []\n",
    "        indexed[get_precursor(y.seq, pc)].append(y)\n",
    "    indexed = collections.OrderedDict(sorted(indexed.items(),key=lambda t: t[0]))\n",
    "    return indexed\n",
    "    \n",
    "def get_hybrid_matches(b_sorted_clusters, y_sorted_clusters, obs_prec, precursor_tol, charge):\n",
    "    merged_seqs = []\n",
    "    ind_b, ind_y = index_by_precursor_mass(b_sorted_clusters, charge),index_by_precursor_mass(y_sorted_clusters, charge)\n",
    "    for i, cluster in enumerate(b_sorted_clusters[:10]):\n",
    "        cluster_seq = cluster.seq\n",
    "        cluster_mass = get_precursor(cluster_seq, charge)\n",
    "        tol = utils.ppm_to_da(obs_prec, precursor_tol)\n",
    "        if not (cluster_mass > obs_prec + tol):\n",
    "            diff = obs_prec + tol - cluster_mass + (charge * PROTON_MASS) + WATER_MASS\n",
    "            merges = grab_matches(cluster,ind_y, diff, 'b')\n",
    "            [merged_seqs.append(x) for x in merges]\n",
    "    for i, cluster in enumerate(y_sorted_clusters[:10]):\n",
    "        cluster_seq = cluster.seq\n",
    "        cluster_mass = get_precursor(cluster_seq, charge)\n",
    "        tol = utils.ppm_to_da(obs_prec, precursor_tol)\n",
    "        if not (cluster_mass > obs_prec + tol):\n",
    "            diff = obs_prec + tol - cluster_mass + (charge * PROTON_MASS) + WATER_MASS\n",
    "#             print(get_precursor(cluster_seq + 'DL', charge), obs_prec + tol)\n",
    "            merges = grab_matches(cluster,ind_b, diff, 'y')\n",
    "            [merged_seqs.append(x) for x in merges]\n",
    "\n",
    "    merged_seqs.sort(key=lambda a: a[0], reverse=True)\n",
    "    return merged_seqs\n",
    "\n",
    "#All inputs are the same\n",
    "merged_seqs = clustering.get_hybrid_matches(b_sorted_clusters, y_sorted_clusters, input_spectrum.precursor_mass, precursor_tolerance, input_spectrum.precursor_charge)\n",
    "print(len(merged_seqs))\n",
    "[print(x) for x in merged_seqs[:50]]\n",
    "with open(os.path.join(location, 'merged_seqs.txt'), 'w') as b:\n",
    "    [b.write(str(x) + '\\n') for x in merged_seqs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759606e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def hybrid_filter_by_precursor(mseqs, obs_prec, precursor_tol, charge):\n",
    "    filtered_seqs = []\n",
    "    for comb_seq in mseqs:\n",
    "        b_seq = comb_seq[3][4]\n",
    "        y_seq = comb_seq[4][4]\n",
    "        if b_seq != y_seq:\n",
    "            new_seq = b_seq + y_seq\n",
    "        else:\n",
    "            new_seq = b_seq\n",
    "        tol = utils.ppm_to_da(obs_prec, precursor_tol)\n",
    "        if not (get_precursor(new_seq, charge) > obs_prec + tol):\n",
    "            filtered_seqs.append(comb_seq)\n",
    "    return filtered_seqs\n",
    "\n",
    "merged_seqs = hybrid_filter_by_precursor(merged_seqs, input_spectrum.precursor_mass, precursor_tolerance, input_spectrum.precursor_charge)\n",
    "print(len(merged_seqs))\n",
    "[print(x) for x in merged_seqs[:50]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d9c6fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_overlapping_sequence(b_seq, y_seq, b_start, b_end, y_start):\n",
    "    seq = ''\n",
    "    if y_start > b_end:\n",
    "        return b_seq + y_seq\n",
    "    else:\n",
    "        for i in range(b_start, y_start):\n",
    "            seq = seq + b_seq[i]\n",
    "        return seq\n",
    "def overlap(comb_seq):\n",
    "    b_seq = comb_seq[3][4]\n",
    "    y_seq = comb_seq[4][4]\n",
    "    b_pid = comb_seq[3][0]\n",
    "    y_pid = comb_seq[4][0]\n",
    "    if b_pid == y_pid:\n",
    "        y_start = comb_seq[4][1]\n",
    "        b_end = comb_seq[3][2]\n",
    "        if (y_start - b_end > 0) & (y_start - b_end < 10):\n",
    "            b_start = comb_seq[3][1]\n",
    "            return get_overlapping_sequence(b_seq, y_seq, b_start, b_end, y_start)\n",
    "        else:\n",
    "            return b_seq + y_seq\n",
    "    else:\n",
    "        return b_seq + y_seq\n",
    "\n",
    "def comb_seq_precursor(comb_seq, obs_prec, precursor_tol, charge): #Currently unused. Created for testing how close initial hits are to the precursor\n",
    "    new_seq = overlap(comb_seq)\n",
    "    tol = utils.ppm_to_da(obs_prec, precursor_tol)\n",
    "    return obs_prec + tol - get_precursor(new_seq, charge)\n",
    "\n",
    "def find_next_mass(comb_seq, ion):\n",
    "    if ion == 'b':\n",
    "        b_tup = comb_seq[3]\n",
    "        target_index = b_tup[2]\n",
    "        target_prot = b_tup[0]\n",
    "        for i, prot_name in enumerate(db.proteins):\n",
    "            if i == target_prot:\n",
    "                protein = db.proteins[prot_name]\n",
    "                prot_seq = protein[0][1]\n",
    "                to_add = prot_seq[target_index] if target_index < len(prot_seq) else ''\n",
    "                    \n",
    "    else:\n",
    "        y_tup = comb_seq[4]\n",
    "        target_index = y_tup[1]\n",
    "        target_prot = y_tup[0]\n",
    "        for i, prot_name in enumerate(db.proteins):\n",
    "            if i == target_prot:\n",
    "                protein = db.proteins[prot_name]\n",
    "                prot_seq = protein[0][1]\n",
    "                to_add = prot_seq[target_index] if target_index < len(prot_seq) else ''\n",
    "    \n",
    "    return to_add\n",
    "\n",
    "def in_tol(mass, tolerance, queried_mass):\n",
    "    if queried_mass >= mass - tol:\n",
    "        if queried_mass <= mass + tol:\n",
    "            return True\n",
    "    return False\n",
    "def filter_by_missing_mass(mseqs, obs_prec, precursor_tol, charge):\n",
    "    filtered_seqs = []\n",
    "    for comb_seq in mseqs:\n",
    "        new_seq = overlap(comb_seq)\n",
    "        tol = utils.ppm_to_da(obs_prec, precursor_tol)\n",
    "        dif = obs_prec + tol - get_precursor(new_seq, charge)\n",
    "#         if in_tol(obs_prec, tol, get_precursor(new_seq, charge))\n",
    "        if dif <= 1: #tol can vary but i'm not sure how much. Tol is .05 for spec 4 Other hacks are 2*tol\n",
    "#             print(obs_prec, get_precursor(new_seq, charge), comb_seq)\n",
    "            filtered_seqs.append(comb_seq)\n",
    "        else:\n",
    "            next_b = find_next_mass(comb_seq, 'b')\n",
    "            b_seq = comb_seq[3][4]\n",
    "            y_seq = comb_seq[4][4]\n",
    "            b_dif = obs_prec + tol - get_precursor(b_seq + next_b + y_seq, charge)\n",
    "            next_y = find_next_mass(comb_seq, 'y')\n",
    "            y_dif = obs_prec + tol - get_precursor(b_seq + next_y + y_seq, charge)\n",
    "            if b_dif >= 0 and y_dif >= 0:\n",
    "                filtered_seqs.append(comb_seq)\n",
    "                \n",
    "#             if in_tol(obs_prec, tol, get_precursor(b_seq + next_b + y_seq, charge)): #For when the entire alignment is coded\n",
    "#                 filtered_seqs.append(comb_seq)\n",
    "#             else:\n",
    "\n",
    "    return filtered_seqs\n",
    "\n",
    "merged_seqs = filter_by_missing_mass(merged_seqs, input_spectrum.precursor_mass, precursor_tolerance, input_spectrum.precursor_charge) \n",
    "print(len(merged_seqs))\n",
    "[print(x) for x in merged_seqs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653d234e",
   "metadata": {},
   "source": [
    "# Alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca3b306",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, comb_seq in enumerate(merged_seqs):\n",
    "    b_seq = comb_seq[3][4]\n",
    "    y_seq = comb_seq[4][4]\n",
    "    if b_seq == \"DPQV\" and y_seq == \"DPQVAQLELGGGPGAG\":\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f1e310",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def modified_find_next_mass(cluster, ion):\n",
    "    if ion == 'b':\n",
    "        target_index = cluster[2] + 1\n",
    "    else:\n",
    "        target_index = cluster[1]-1\n",
    "    target_prot = cluster[0]\n",
    "    for i, prot_name in enumerate(db.proteins):\n",
    "        if i == target_prot:\n",
    "            protein = db.proteins[prot_name]\n",
    "            prot_seq = protein[0][1]\n",
    "            to_add = prot_seq[target_index] if (target_index < len(prot_seq) and target_index > 0) else ''\n",
    "    \n",
    "    return to_add\n",
    "\n",
    "def make_merge(b, y, b_seq, y_seq):\n",
    "    new_b = (b[0], b[1], b[2], b[3], b_seq)\n",
    "    new_y = (y[0], y[1], y[2], y[3], y_seq)\n",
    "    return (b[3] + y[3], b[1] - y[2], y[2]-b[1], new_b, new_y)\n",
    "\n",
    "def add_amino_acids(alignment_list, missing_mass, b_c, y_c, comb_seq, b_seq, y_seq, precursor_charge, prec_mass, tol):\n",
    "    #This function recursively adds in amino acids    \n",
    "    if abs(get_precursor(b_seq + y_seq, precursor_charge) - prec_mass) <= tol:\n",
    "        alignment_list.add(make_merge(b_c, y_c, b_seq, y_seq))\n",
    "        return\n",
    "    \n",
    "    if get_precursor(b_seq + y_seq, precursor_charge) > prec_mass + tol:\n",
    "        return\n",
    "    \n",
    "    next_b = modified_find_next_mass(b_c, 'b')\n",
    "    next_y = modified_find_next_mass(y_c, 'y')\n",
    "    \n",
    "    if get_precursor(b_seq + y_seq, precursor_charge) < prec_mass - tol and (next_b != \"\"):\n",
    "        mod_b = b_seq + next_b\n",
    "        mod_b_c = (b_c[0], b_c[1], b_c[2]+1, b_c[3], mod_b)\n",
    "        add_amino_acids(alignment_list, missing_mass, mod_b_c, y_c, comb_seq, mod_b, y_seq, precursor_charge, prec_mass, tol)\n",
    "    if get_precursor(b_seq + y_seq, precursor_charge) < prec_mass - tol and (next_y != \"\"):\n",
    "        mod_y = next_y + y_seq\n",
    "        mod_y_c = (y_c[0], y_c[1]-1, y_c[2], y_c[3], mod_y)\n",
    "        add_amino_acids(alignment_list, missing_mass, b_c, mod_y_c, comb_seq, b_seq, mod_y, precursor_charge, prec_mass, tol)\n",
    "        \n",
    "    return\n",
    "\n",
    "        \n",
    "def find_alignments(merged_seqs, obs_prec, prec_charge, tol):\n",
    "    alignments = set()\n",
    "    for comb_seq in merged_seqs:\n",
    "        b_cluster = comb_seq[3]\n",
    "        y_cluster = comb_seq[4]\n",
    "        b_seq = comb_seq[3][4]\n",
    "        y_seq = comb_seq[4][4]\n",
    "        if b_seq != y_seq:\n",
    "            new_seq = b_seq + y_seq\n",
    "            missing_mass = obs_prec - get_precursor(new_seq, prec_charge)\n",
    "            add_amino_acids(alignments, missing_mass, b_cluster, y_cluster, comb_seq, b_seq, y_seq, prec_charge, obs_prec, tol)            \n",
    "        else:\n",
    "            new_seq = b_seq\n",
    "            if (abs(get_precursor(new_seq, prec_charge) - obs_prec) <= tol):\n",
    "                alignments.add(comb_seq)\n",
    "            \n",
    "    return alignments\n",
    "\n",
    "tol = utils.ppm_to_da(input_spectrum.precursor_mass, precursor_tolerance)\n",
    "alignments = find_alignments(merged_seqs[:50], input_spectrum.precursor_mass, input_spectrum.precursor_charge, tol)\n",
    "print(alignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b75f12",
   "metadata": {},
   "source": [
    "# Second Round of Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3574d3ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def score_by_dist(merged_seqs, obs_prec, precursor_tol, charge):\n",
    "    new_list = []\n",
    "    for comb_seq in merged_seqs:\n",
    "        b_seq = comb_seq[3][4]\n",
    "        y_seq = comb_seq[4][4]\n",
    "        if b_seq != y_seq:\n",
    "            new_seq = b_seq + y_seq\n",
    "        else:\n",
    "            new_seq = b_seq\n",
    "        tol = utils.ppm_to_da(obs_prec, precursor_tol)\n",
    "        dist = abs(get_precursor(new_seq, charge) - obs_prec)\n",
    "        new_list.append((dist, comb_seq))\n",
    "    return new_list\n",
    "    \n",
    "print(\"SpecMill Sequence Dist:\", abs(input_spectrum.precursor_mass - get_precursor(correct_sequence, input_spectrum.precursor_charge)))\n",
    "new_merges = score_by_dist(alignments, input_spectrum.precursor_mass, 10, input_spectrum.precursor_charge)\n",
    "new_merges.sort(key=lambda a: a[0])\n",
    "[print(x) for x in new_merges[:50]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16fe64f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_total_score(sequence, i_spectrum, ppm_tol):\n",
    "    total_score = 0\n",
    "    spectrum = gen_spectrum(sequence)\n",
    "    masses = sorted(spectrum['spectrum'])\n",
    "    o_ctr, t_ctr = 0, 0\n",
    "    observed = i_spectrum[o_ctr]\n",
    "    theoretical = masses[t_ctr]\n",
    "    tol = utils.ppm_to_da(observed, ppm_tol)\n",
    "    while (o_ctr < len(i_spectrum) and t_ctr < len(masses)):\n",
    "        if theoretical < observed - tol:\n",
    "            t_ctr = t_ctr + 1\n",
    "            if t_ctr < len(masses):\n",
    "                theoretical = masses[t_ctr]\n",
    "        elif observed + tol < theoretical:\n",
    "            o_ctr = o_ctr + 1\n",
    "            if o_ctr < len(i_spectrum):\n",
    "                observed = i_spectrum[o_ctr]\n",
    "            tol = utils.ppm_to_da(observed, ppm_tol)\n",
    "        elif observed - tol <= theoretical and observed + tol >= theoretical:\n",
    "            total_score = total_score + 1\n",
    "            o_ctr = o_ctr + 1\n",
    "            t_ctr = t_ctr + 1\n",
    "            if o_ctr < len(i_spectrum) and t_ctr < len(masses):\n",
    "                observed = i_spectrum[o_ctr]\n",
    "                theoretical = masses[t_ctr]\n",
    "                tol = utils.ppm_to_da(observed, ppm_tol)\n",
    "        \n",
    "    return(total_score)\n",
    "\n",
    "def find_for_all(merged_seqs, i_spectrum, ppm_tol):\n",
    "    new_list = []\n",
    "    for comb_seq in merged_seqs:\n",
    "        b_seq = comb_seq[3][4]\n",
    "        y_seq = comb_seq[4][4]\n",
    "        if b_seq != y_seq:\n",
    "            new_seq = b_seq + y_seq\n",
    "        else:\n",
    "            new_seq = b_seq\n",
    "        score = find_total_score(new_seq, i_spectrum, ppm_tol)\n",
    "        new_list.append((score, comb_seq))\n",
    "        \n",
    "    new_list.sort(key=lambda a: a[0], reverse = True)\n",
    "    return new_list\n",
    "    \n",
    "    \n",
    "print(\"SpecMill Sequence Total Score:\", find_total_score(correct_sequence, input_spectrum.mz_values, ppm_tolerance))\n",
    "tol = utils.ppm_to_da(input_spectrum.precursor_mass, 10)\n",
    "print(input_spectrum.precursor_mass, get_precursor(correct_sequence, input_spectrum.precursor_charge), abs(input_spectrum.precursor_mass - get_precursor(correct_sequence, input_spectrum.precursor_charge)))\n",
    "rescored_merges = find_for_all(alignments, input_spectrum.mz_values, ppm_tolerance)\n",
    "[print(x) for x in rescored_merges[:50]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f15ed2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
